Até agora nos preocupamos apenas com problemas com uma variável de estado e
uma variável de controle. Nesse capítulo vamos estudar as condições
necessárias para um problema com mais de uma variável de cada tipo, dado que
em problemas reais, vários objetos interagem entre si. 

\section{Condições necessárias}

Faremos uma extensão natural dos problemas desenvolvidos até então. Seja o
problema com $n$ variáveis de estado, $m$ variáveis de controle e uma função
\textit{payoff} $\phi$. 
$$
\max_{u_1,...,u_m} \int_{t_0}^{t_1} f(t,x_1(t),...,x_n(t),u_1(t),...,u_m(t)) dt + \phi(x_1(t_1),...,x_n(t_1))
$$
$$
\text{sujeito a   }x_i'(t) = g_i(t,x_1(t),...,x_n(t),u_1(t),...,u_m(t))
$$
$$
x_i(t_0) = x_{i0} \text{ para }i=1,2,...,n
$$
onde as funções $f$ e $g_i$ são continuamente diferenciáveis em cada variável.
Em notação vetorial, seja $\vec{x}(t), \vec{u}(t), \vec{g}(t,\vec{x},\vec{u})
\text{ e } \vec{x}_0$ os vetores, respectivamente, do estado, do controle, das
funções derivada dos estados e da condição inicial. Podemos escrever o problema,
portanto, como 
$$
\max_{\vec{u}} \int_{t_0}^{t_1} f(t,\vec{x}(t),\vec{u}(t)) dt + \phi(\vec{x}(t_1))
$$
$$
\text{sujeito a   }\vec{x}'(t) = \vec{g}(t,\vec{x}(t), \vec{u}(t)), \vec{x}(t_0) = \vec{x}_{0} 
$$


Seja $\vec{u}^*$ o vetor de funções controle ótimo e $\vec{x}^*$ o vetor de
estados correspondente. Seja $\vec{\la}(t) = [\la_1(t),...,\la_n(t)]$ um vetor
com funções diferenciáveis por partes, que serão as funções adjuntas. Defina o
Hamiltoniano
$$H(t,\vec{x},\vec{u},\vec{\la}) = f(t,\vec{x},\vec{u}) + \vec{\la}(t)\cdot
\vec{g}(t,\vec{x},\vec{u}),$$
onde $(\cdot)$ é o produto escalar de vetores. Pelo mesmo argumento apresentado
no capítulo \ref{ch:1}, encontramos que $\vec{u}^*$ maximiza a função $\vec{u}
\mapsto H(t, \vec{x}^*, \vec{u}, \vec{\lambda})$ e satisfaz 
$$
x'_i(t) = \frac{\partial H}{\partial \la_i} = g_i(t,\vec{x},\vec{u}), x_i(0) = x_{i0} \text{ para }i = 1,...n 
$$
$$
\la'_j(t) = - \frac{\partial H}{\partial x_j}, \la_j(t_1) = \phi_{x_j}(\vec{x}(t_1)) \text{ para }j=1,...,n
$$
$$
0 = \frac{\partial H}{\partial u_k} \text{ em }u^*_k \text{ para }k=1,...,m
$$

Modificações nesse problema, como, por exemplo, imposição de limites inferior
e superior no controle, ou imposição do valor final para o estado, repercutem
no caso multivariado, com extensões similares. A dualidade entre $x_i$ e
$\lambda_i \text{ para }i=1,...,n$ ainda é observada. Nesse caso, as condições
unidimensionais são calculadas para cada componente dos vetores. 

\begin{example}
    \begin{gather*}
        \min_u \int_0^1 x_2(t) + u(t)^2 dt \\
        \text{sujeito a  }x_1'(t) = x_2(t), x_1(0) = 0, x_1(1) = 1, \\
        x_2 '(t) = u(t), x_2(0) = 0, \\
        a \le u(t) \le b
    \end{gather*}
\end{example}

Sejam $\la_1$ e $\la_2$ variáveis adjuntas e defina 
$$
H = x_2 + u^2 + \la_1x_2 + \la_2 u
$$
As equações adjuntas são dadas por 
\begin{align*}
    &\la_1 '(t) = -\frac{\partial H}{\partial x_1} = 0 \implies \la_1(t) \equiv C \\
    &\la_2 '(t) = -\frac{\partial H}{\partial x_2} = - 1 - \la_1 \implies \la_2(t) = -(1 + C)t + D.
\end{align*}

As condições de transversalidade serão as seguintes: para a primeira variável,
elas serão livres, enquanto para a segunda variável, teremos 
$$\la_2(1) = 0 \implies D = 1 + C \implies \la_2(t) = -(1 + C)(t-1).$$ 

Usando as condições de otimalidade, obtemos 
$$
H_u = 2u + \la_2 
$$

Lembrando que o problema é de minimização,
\begin{gather*}
    H_u > 0 \implies u^*(t) = a \implies -\frac{1}{2}\la_2 < a \\
    H_u < 0 \implies u^*(t) = b \implies -\frac{1}{2}\la_2 > b \\
    H_u = 0  \implies a \le u^*(t) =  -\frac{1}{2}\la_2(t) \le b 
\end{gather*}

Usando o fato de que $-\frac{1}{2}\la_2(t) = \frac{1+C}{2}(t-1)$

$$
u^*(t) = \begin{cases}
    a &t < \frac{2}{1 + C} a + 1 \\
    \frac{1 + C}{2}(t-1) &t \in \left[\frac{2}{1 + C} a + 1, \frac{2}{1 + C}b + 1\right] \\
    b &t > \frac{2}{1 + C}b + 1
\end{cases}
$$

Para encontrar o valor da constante $C$, algumas complicações com a relação às
contas são necessárias e, por esse motivo, não constam no texto. O que precisa
ser feito é o seguinte: primeiro integramos a equação $x_2 ' = u$, 
assegurando a continuidade de $x_2$ nos pontos $t = \frac{2}{1 + C} a + 1
\text{ e } t = \frac{2}{1 + C} b + 1$ e considerando a sua condição inicial
$x_2(0) = 0$; depois integramos a equação $x_1 ' = x_2$ e usamos as condições
de continuidade nos mesmos pontos em $x_1$ e, por fim, as condições de
contorno $x_1(0) = 0, x_1(1) = 1$.


\section{Problemas de regulador linear quadrático}

Nessa seção será desenvolvido um caso especial de sistemas de controle ótimo,
em que as equações diferenciais são lineares em $x$ e $u$ e o funcional
objetivo é quadrático. Assim descrevemos o problema da seguinte forma: 
$$
J(u) := \frac{1}{2}[x^T(T)Mx(t) + \int_0^T x^T(t)Q(t)x(t) + u^TR(t)u(t) dt]
$$
$$
x'(t) = A(t)x(t) + B(t)u(t), x(0) = x_0
$$
onde $x \in \mathbb{R}^n, u \in \mathbb{R}^m, A(t) \in \mathbb{R}^{n \times n}$
e $B(t) \in \mathbb{R}^{n\times m}$. Além disso $M, Q(t)$ são positivas
semidefinidas e $R(t)$ é positiva definida para garantir invertibilidade, para
todo $t$ em $[0,T]$. As três matrizes são simétricas, a fim de garantir a 
diagonalização. O Hamiltoniano é, portanto, 
$$H = \frac{1}{2}x^TQx + \frac{1}{2}u^TRu + \la^T(Ax + Bu).$$

A operação de derivação de expressões matriciais é uma ferramenta poderosa,
pois simplifica a notação do problema e, por isso será utilizada aqui.
Todavia, é importante que se conheça o processo da diferenciação. A simetria
das matrizes é utilizada nesse passo. 

A equação de otimalidade é dada por 
$$
H_u = Ru + B^T\lambda = 0 \implies u^* = - R^{-1}B^T\la,
$$
enquanto a equação adjunta é dada por 
$$
\la' = -H_x = -Qx - A^T\la, \la(T) = Mx(T)
$$

Para resolvermos esse problema, utilizaremos o método \textit{sweep}. Para
isso, vamos encontrar uma matriz $S(t)$ de forma que $\la(t) = S(t)x(t)$.
Assim 
$$
\la ' = S'x + Sx' = S'x + S(Ax + Bu) = -Qx -A^T(Sx)
$$
Utilizando a condição de otimalidade, 
\begin{equation*}
    \begin{split}
        -S'x &= Qx + A^TSx + SAx - SBR^{-1}B^TSx \\
        &= (Q + A^TS + SA - SBR^{-1}B^TS)x
    \end{split}
\end{equation*}

Temos, portanto, a equação matricial de \textit{Ricatti}
$$
-S' = A^TS + SA - SBR^{-1}B^TS + Q, S(T) = M
$$

Esse controle é um tipo de controle \textit{feedback}, pois é uma função
linear do estado apenas. A matriz $R^{-1}B^TS$ é chamada e \textit{gain}. O
interessante dessa solução é que eliminamos a necessidade da função adjunta. 

\begin{example}
    \begin{gather*}
        \min_u \frac{1}{2}\int_0^T x(t)^2 + u(t)^2 dt \\
        \text{sujeito a  }x'(t) = u(t), x(0) = x_0
    \end{gather*}
\end{example}

Nesse caso $M = A = 0$ e $B = R = Q = 1$. Pela equação de Ricatti, 
$$
-S' = - S^2 + 1, S(T) = 0 \implies S(t) = \frac{1 - Ce^{2t}}{1 + Ce^{2t}},
$$
tal que $S(T) = \dfrac{1 - Ce^{2T}}{1 + Ce^{2t}} = 0 \implies C =
e^{-2T}$, isto é, 
$$
S(t) = \frac{1 - e^{2(t-T)}}{1 + e^{2(t-T)}}
$$

Temos que $u^*(t) = - R^{-1}B^TSx = -Sx$ e precisamos, portanto, encontrar o
valor de $x$ primeiro. Através da equação diferencial $x'(t) = -Sx$, 
$$x^*(t) = e^{-\int S dt}$$

$$
\int  \frac{1 - e^{2(t-T)}}{1 + e^{2(t-T)}}dt = t - \log(e^{2(t-T)} + 1) + K'
$$
tal que $x_0 = x^*(0) = e^{\log(e^{-2T} + 1)}K, K = e^{-K'} \implies K =
\frac{x_0}{e^{-2T} + 1}$. 

Portanto, 
$$
x^*(t) = \frac{x_0}{e^{-2T} + 1}e^{\log(e^{2(t-T)} + 1) - t}
$$
$$
u^*(t) = -\frac{1 - e^{2(t-T)}}{1 + e^{2(t-T)}}\frac{x_0}{e^{-2T} + 1}e^{\log(e^{2(t-T)} + 1) - t}
$$


\section{Equações diferenciais de ordem mais alta}

Quando temos uma equação diferencial de ordem mais alta - quando aparecem
$x^{(k)}, k > 1$ - relacionada ao estado,
podemos definir um sistema de equações diferenciais, de forma que $x_1(t) = x(t), x_2(t) = x'(t), ...,
x_{n+1}(t) = x^{(n)}(t)$. A partir dessa transformação, podemos resolver o
problema com o Princípio Máximo de Pontryagin. 

\section{Restrições isoperimétricas}

Ao invés de tomar limites inferior e superior com relação ao controle, podemos
restringir a integral sobre uma função do controle, assim, podemos ter o
seguinte problema, sendo $f, g, h$ funções continuamente diferenciáveis nas
três variáveis. 
\begin{gather*}
    \max_u \int_{t_0}^{t_1} f(t, x(t), u(t)) dt + \phi(x(t_1)) \\ 
    \text{sujeito a  }x'(t) = g(t, x(t), u(t)), x(t_0) = x_0, \\
    \int_{t_0}^{t_1} h(t, x(t), u(t)) dt = B, \\
    a \le u(t) \le b
\end{gather*}

Esse tipo de restrição é conhecido como \textit{restrição isoperimétrica}. De
fato não podemos lidar de forma direta com esse problema pelo Principio Máximo
de Pontryagin. Entretanto, podemos introduzir uma segunda variável $z(t)$ tal
que 
$$
z(t) = \int_{t_0}^t h(s,x(s),u(s))ds
$$
e, portanto, 
\begin{gather*}
    z'(t) = h(t,x(t),u(t)), \\
    z(t_0) = 0, \\
    z(t_1) = B
\end{gather*}

A partir disso, podemos resolver através do método estudado até então. 

\section{Soluções numéricas}

O método para resolver esses sistemas numericamente é basicamente o mesmo.
Primeiro, fazemos um chute inicial para cada controle. Depois resolvemos
simultaneamente os estados para frente no tempo. Então resolvemos todas as
adjuntas simultaneamente para trás no tempo. Cada controle é então atualizado
segundo sua caracterização. Esse processo ocorre iterativamente até atingir
convergência desejada. Usaremos o método Runge-Kutta para sistemas na
integração. O método de Runge-Kutta vetorial precisa resolver $\vec{k}_1$
inicialmente, ou seja, $k_1^i$ para cada estado $x_i$, para então resolver
$\vec{k}_2$. 