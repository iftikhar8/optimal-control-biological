Após desenvolver as condições necessárias para resolver o problema de controle
ótimo inicial, alguns problemas podem surgir. Como assumimos a existência de
controle ótimo, podemos encontrar uma função de controle pelas condições mesmo
quando não haja. Também pode ser obtido um funcional que tem valor infinito, algo que não
desejado. Portanto, se o funcional objetivo tiver valor mais ou menos
infinito, o problema não tem solução. 

\section{Existência e Unicidade}

\begin{theorem}
    Seja $$J(u) := \int_{t_0}^{t_1} f(t,x(t),u(t))dt$$ 
    $$\text{sujeito a } x'(t) = g(t,x(t),u(t)), x(t_0) = x_0.$$ 
    Suponha que $f(t,x,u)$ e $g(t,x,u)$ sejam continuamente diferenciáveis nos
    três argumentos e côncavos no segundo e terceiro argumentos. Suponha que
    $u^*$ é um controle, com estado associado a $x^*$, a $\la$ uma função
    diferenciável por partes, tal que $t_0 \le t \le t_1$: 
    \begin{subequations}
        \label{eq:conditions}
        \begin{align}
            f_u + \la g_u &= 0, \label{rel1} \\
            \la ' &= - (f_x + \la g_x),  \label{rel2} \\ 
            \la(t_1) &= 0, \label{rel3} \\
            \la(t) &\ge 0. \label{rel4}
        \end{align}
    \end{subequations}
    Então, para todos os controles $u$, $J(u^*) \ge J(u)$. 
\end{theorem}

\begin{proof}
    Seja $u$ um controle qualquer. Assim, usando a concavidade de $f$,
    \begin{equation}
        \label{eq:first-result}
        \begin{split}
            J(u^*) - J(u) &= \int_{t_0}^{t_1} f(t, x^*, u^*) - f(t,x,u) dt \\
            &\ge \int_{t_0}^{t_1} (x^{*}(t) - x(t))f_x(t, x^*, u^*) \\ 
            &~~+ (u^*(t) - u(t))f_u(t, x^*, u^*)dt
        \end{split}
    \end{equation}
    Aplicando \refeq{rel1} e \refeq{rel2} ao último termo de
    \refeq{eq:first-result}, ele será 
    \begin{equation*}
        \begin{split}
            \int_{t_0}^{t_1} &(x^{*}(t) - x(t))(-\la(t)g_x(t,x^*, u^*) - \la '(t)) \\ 
            &+ (u^*(t) - u(t))(-\la(t)g_u(t,x^*, u^*))dt.
        \end{split}
    \end{equation*}
    Integrando por partes, com $\la(t_1) = 0$ e $x(t_0) = x^*(t_0)$, vemos que
    \begin{equation*}
        \begin{split}
            \int_{t_0}^{t_1} -\la '(t)(x^*(t) - x(t))dt &= -\cancel{(x^*(t) - x(t))\la(t)\bigg\rvert_{t_0}^{t_1}} \\ 
            &~~~~+ \int_{t_0}^{t_1}\la(t)(x^*(t) - x(t))'dt \\
            &= \int_{t_0}^{t_1}\la(t)(g(t,x^*(t),u^*(t)) - g(t,x(t),u(t)))dt
        \end{split}
    \end{equation*}
    Substituindo e usando tanto a concavidade de $g$ quanto \refeq{rel4},
    \begin{equation*}
        \begin{split}
            J(u^*) - J(u) \ge \int_{t_0}^{t_1} &\la(t)[g(t, x^*, u^*) - g(t,x,u) - \\
            &(x^* - x)g_x(t,x^*, u^*) - (u^* - u)g_u(t, x^*, u^*)]dt \\
            \ge 0 ~~~~&
        \end{split}
    \end{equation*}
\end{proof}

Falta garantir que $J(u^*)$ seja finito. Para isso, algumas restrições sobre
$f$ e/ou $g$ são necessárias. O próximo teorema é um exemplo sobre isso. 

\begin{theorem}
    Seja $u \in L([t_0,t_1];\mathbb{R})$, $f$ é convexa em $u$, e existam
    constantes $C_4$ e $C_1$,$C_2$,$C_3 >0$ e $\beta > 1$, tal que, $\forall t
    \in [t_0, t_1], x, x_1, u \in \mathbb{R}$. 
    \begin{equation*}
        \begin{cases}
            g(t,x,u) = \alpha (t,x) + \beta (t,x)u \\
            |g(t,x,u)| \leq C_1(1 + |x| + |u|) \\
            |g(t,x_1,u) - g(t,x,u)| \leq C_2|x_1 - x|(1 + |u|) \\
            f(t,x,u) \geq C_3|u|^{\beta} - C_4
        \end{cases}
    \end{equation*}
    Então existe um controle ótimo $u^*$ maximizando $J(u)$ com $J(u^*)$
    finito. 
\end{theorem}

Em problemas de minimização, $g$ seria côncava e a desigualdade de $f$ é
revertida. Podemos extender as condições necessárias para funções de controle
Lebesgue integráveis, mas isso não é feito aqui. Alguns resultados de
existência de controle ótimo podem ser encontrados em \cite{filippov1962}. 

\Space

\textbf{Unicidade:} Unicidade de soluções do sistema de otimalidade implica unicidade
do controle ótimo, se existir. Em geral, podemos provar a unicidade de
soluções do sistema de otimalidade em intervalos de tempo curtos. A volta nem
sempre é verdadeira, isto é, unicidade do controle ótimo não garante a
unicidade do sistema. 

Os exemplos e laboratórios satisfazem as condições de existência e unicidade
para intervalos de tempo pequenos. Portanto, resolver através das condições
necessárias já se torna suficiente. 

\section{Interpretação da Adjunta}

Defina 
$$
V(x_0, t_0) := \max_u \int_{t_0}^{t_1} f(t,x(t), u(t)) dt
$$
$$
\text{sujeito a } x'(t) = g(t,x,u), x(t_0) = x_0.
$$
Estabelecemos que 
$$\frac{\partial V}{\partial x}(x_0, t_0) = \lim_{\e \to 0} \frac{V(x_0 + \e,
t_0) - V(x_0,t_0)}{\e} = \la(t_0).$$

Podemos relacionar, então, a função adjunta à variação marginal da função
custo/lucro com respeito ao estado. É o valor adicional associado com um 
incremento adicional da variável de estado. Na verdade, essa aproximação é
válida para todo tempo $t$ \cite[136-139]{kamien2012dynamic}. Podemos aproximar: 

\begin{equation*}
    V(x_0 + \e,t_0) \approx V(x_0,t_0) + \e\la(t_0). 
\end{equation*}
Se $\e = 1$, podemos ver que ao adicionar um unidade à condição inicial,
$\la(t_0)$ será adicionado ao lucro resultante. 

\section{Princípio da Otimalidade}

É um resultado importante sobre otimizar um sistema sobre um subintervalo do
intervalo original e, em particular, como o controle ótimo nesse subintervalo
se relaciona com o controle no intervalo inteiro. 

\begin{theorem}
    Considere $u^*$ o controle ótimo associado ao estado $x^*$ para o problema
    $$
    \max_u J(u) = \max_u \int_{t_0}^{t_1} f(t, x(t), u(t)) dt 
    $$
    $$
    \text{sujeito a  }x'(t) = g(t, x(t), u(t)), x(t_0) = x_0.
    $$
    Seja $\hat{t} \in (t_0, t_1)$ fixo. Então as
    funções $\hat{u}^*$ e $\hat{x}^*$ restritas ao intervalo $[\hat{t},t_1]$ 
    formam uma solução ótima para o problema 
    $$
    \max_u \hat{J}(u) = \max_u \int_{t_0}^{t_1} f(t, x(t), u(t)) dt 
    $$
    $$
    \text{sujeito a  }x'(t) = g(t, x(t), u(t)), x(\hat{t}) = x^*(\hat{t}).
    $$
    Além disso, se $u^*$ é controle ótimo único, então
    $\hat{u}^*$ é também. 
\end{theorem}

\begin{proof}
    Esta prova se dá por contradição. Suponha que $\hat{u}^*$ não seja ótimo,
    isto é, exista uma função de controle $\hat{u}_1$ no intervalo $[\hat{t},
    t_1]$ tal que $\hat{J}(\hat{u}_1) > \hat{J}(\hat{u}^*)$. Defina 
    $$u_1(t) = 
    \begin{cases}
        u^*(t), &t \in [t_0, \hat{t}] \\
        \hat{u}_1(t), &t \in [\hat{t}, t_1]
    \end{cases}
    $$
    Seja $x_1$ o estado associado a $u_1$. Assim 
    \begin{equation*}
        \begin{split}
            J(u_1) - J(u^*) &= \left(\int_{t_0}^{\hat{t}} f(t,x_1,u_1)dt +
            \hat{J}(\hat{u}_1)\right) - \left(\int_{t_0}^{\hat{t}} f(t,x^*,u^*)dt +
            \hat{J}(\hat{u}^*)\right) \\
            &= \hat{J}(\hat{u}_1) - \hat{J}(\hat{u}^*) > 0 
        \end{split}        
    \end{equation*}
    Isso contradiz a hipótese inicial de que $u^*$ é controle ótimo. 
\end{proof}

\begin{remark}
    Note que nada pode ser dito sobre o intervalo $[t_0, \hat{t}]$, pois podemos construir contra-exemplos. 
\end{remark}

\section{Os Problemas Autônomo e Hamiltoniano}

\begin{theorem}
    O Hamiltoniano é uma função contínua Lipschitz do tempo $t$ no caminho
    ótimo. 
\end{theorem}

\begin{definition}[Autônomo]
    Se um problema de controle ótimo não tem dependência explícita do tempo,
    ele é dito autônomo. Isso significa que $f$ e $g$, em nossa notação, são
    funções apenas de $x$ e $u$. 
\end{definition}

\begin{theorem}
    Se um problema de controle ótimo é autônomo, então o Hamiltoniano é uma
    função constante do tempo ao longo da solução ótima. 
\end{theorem}

\section{Exemplos}

\begin{example}
    Queremos resolver o problema 
    $$
    \min_u \int_{t_0}^{t_1} x(t) + \frac{1}{2}u(t)^2 dt
    $$
    $$  
    \text{sujeito a  }x'(t) = x(t) + u(t), x(0) = \frac{1}{2}e^2 - 1
    $$
    no intervalo $[0,2]$ e, posteriormente, no intervalo $[1,2]$.
\end{example}

Observe inicialmente que $f$ e $g$ são continuamente diferenciáveis e convexos no segundo 
e terceiro argumentos, dado que o problema é de minimização. Vamos então conferir as condições 
necessárias e, então, saberemos que $J(u^*) \le J(u)$ para toda função de controle $u$, pelo 
teorema de existência. 

\Space

O Hamiltoniano é 
$$
H = x + \frac{1}{2}u^2 + x \la + u \la
$$
A equação adjunta é dada por 
$$
\la ' = - H_x = -1 - \la, \la(2) = 0 \implies \la(t) = e^{2-t} -1 \ge 0,
$$
A condição de otimalidade é dada por 
$$
H_u = u + \la = 0 \implies u^*(t) = -\la(t) = 1 - e^{2-t} 
$$
E, portanto 
$$
x'(t) - x(t) = 1 - e^{2-t} \implies x(t) = Ce^t + \frac{1}{2}e^{2-t} - 1
$$
Usando a condição inicial 
$$
\frac{1}{2}e^2 - 1 = C + \frac{1}{2}e^{2} - 1 \implies x^*(t) =  \frac{1}{2}e^{2-t} - 1   
$$

Considerando o intervalo em $[1,2]$, vemos que $\hat{u}^* = u^*$ em $[1,2]$. Se fôssemos resolver 
fazendo as contas, veja que todos os passos poderiam ser repetidos, com exceção de que $x(1) = \frac{1}{2}e - 1$, 
o que não mudaria a solução. 

\begin{example}
    Considere o problema acima, mas no intervalo $[0,1]$. 
\end{example}

O Hamiltoniano é o mesmo e $u^*(t) = -\la(t)$. Mas a condição de transversalidade é diferente: 
$\la(1) = 0 \implies \la(t) = e^{1-t} - 1 \text{ e } u^{*}(t) = 1 - e^{1-t}$. 
Ao usarmos a equação do estado, obteremos que 
$$
x^*(t) = \frac{1}{2}e^{1-t} - 1 + \frac{1}{2}(e^2 - e)e^t
$$
Note que a solução é diferente da anterior restrita a $[0,1]$. 